{"cells":[{"cell_type":"markdown","source":["**DRİVE BAĞLANMA**"],"metadata":{"id":"D2tkse1fbkCW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aUSQDK--zp03","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716449283775,"user_tz":-180,"elapsed":29366,"user":{"displayName":"muammer türkoğlu","userId":"14813586314427592235"}},"outputId":"a52e2466-6704-4c90-8bf5-8d05e893c161"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["**KÜTÜPHANELERİ YÜKLEME**"],"metadata":{"id":"jgWWd1etbgst"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5DRF9YLzz7g"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import cv2\n","import os\n","import keras\n","from tqdm import tqdm\n","import tensorflow as tf\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n","from keras.models import Model,Sequential, load_model\n","from tensorflow.keras import Input\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","from keras.applications.vgg16 import VGG16\n"]},{"cell_type":"markdown","source":["**VERİ ÖN YÜKLEME VE İŞLEME**"],"metadata":{"id":"bQbTSGeobp5V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RVWqq47tz4Ta","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716449506308,"user_tz":-180,"elapsed":2517,"user":{"displayName":"muammer türkoğlu","userId":"14813586314427592235"}},"outputId":"135dfd9a-65f0-457c-960c-3265378a6590"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 COVID\n","1 non-COVID\n","[['COVID/Covid (1).png', 0, 'COVID'], ['COVID/Covid (100).png', 0, 'COVID'], ['COVID/Covid (10).png', 0, 'COVID'], ['COVID/Covid (12).png', 0, 'COVID'], ['COVID/Covid (11).png', 0, 'COVID'], ['COVID/Covid (14).png', 0, 'COVID'], ['COVID/Covid (2).png', 0, 'COVID'], ['COVID/Covid (16).png', 0, 'COVID'], ['COVID/Covid (17).png', 0, 'COVID'], ['COVID/Covid (23).png', 0, 'COVID'], ['COVID/Covid (24).png', 0, 'COVID'], ['COVID/Covid (25).png', 0, 'COVID'], ['COVID/Covid (22).png', 0, 'COVID'], ['COVID/Covid (18).png', 0, 'COVID'], ['COVID/Covid (19).png', 0, 'COVID'], ['COVID/Covid (26).png', 0, 'COVID'], ['COVID/Covid (27).png', 0, 'COVID'], ['COVID/Covid (13).png', 0, 'COVID'], ['COVID/Covid (20).png', 0, 'COVID'], ['COVID/Covid (15).png', 0, 'COVID'], ['COVID/Covid (21).png', 0, 'COVID'], ['COVID/Covid (28).png', 0, 'COVID'], ['COVID/Covid (44).png', 0, 'COVID'], ['COVID/Covid (3).png', 0, 'COVID'], ['COVID/Covid (38).png', 0, 'COVID'], ['COVID/Covid (37).png', 0, 'COVID'], ['COVID/Covid (41).png', 0, 'COVID'], ['COVID/Covid (33).png', 0, 'COVID'], ['COVID/Covid (39).png', 0, 'COVID'], ['COVID/Covid (43).png', 0, 'COVID'], ['COVID/Covid (36).png', 0, 'COVID'], ['COVID/Covid (34).png', 0, 'COVID'], ['COVID/Covid (4).png', 0, 'COVID'], ['COVID/Covid (30).png', 0, 'COVID'], ['COVID/Covid (31).png', 0, 'COVID'], ['COVID/Covid (40).png', 0, 'COVID'], ['COVID/Covid (45).png', 0, 'COVID'], ['COVID/Covid (32).png', 0, 'COVID'], ['COVID/Covid (42).png', 0, 'COVID'], ['COVID/Covid (35).png', 0, 'COVID'], ['COVID/Covid (29).png', 0, 'COVID'], ['COVID/Covid (57).png', 0, 'COVID'], ['COVID/Covid (59).png', 0, 'COVID'], ['COVID/Covid (55).png', 0, 'COVID'], ['COVID/Covid (54).png', 0, 'COVID'], ['COVID/Covid (56).png', 0, 'COVID'], ['COVID/Covid (46).png', 0, 'COVID'], ['COVID/Covid (63).png', 0, 'COVID'], ['COVID/Covid (60).png', 0, 'COVID'], ['COVID/Covid (5).png', 0, 'COVID'], ['COVID/Covid (52).png', 0, 'COVID'], ['COVID/Covid (68).png', 0, 'COVID'], ['COVID/Covid (6).png', 0, 'COVID'], ['COVID/Covid (69).png', 0, 'COVID'], ['COVID/Covid (65).png', 0, 'COVID'], ['COVID/Covid (48).png', 0, 'COVID'], ['COVID/Covid (64).png', 0, 'COVID'], ['COVID/Covid (51).png', 0, 'COVID'], ['COVID/Covid (67).png', 0, 'COVID'], ['COVID/Covid (53).png', 0, 'COVID'], ['COVID/Covid (66).png', 0, 'COVID'], ['COVID/Covid (61).png', 0, 'COVID'], ['COVID/Covid (62).png', 0, 'COVID'], ['COVID/Covid (58).png', 0, 'COVID'], ['COVID/Covid (49).png', 0, 'COVID'], ['COVID/Covid (50).png', 0, 'COVID'], ['COVID/Covid (47).png', 0, 'COVID'], ['COVID/Covid (73).png', 0, 'COVID'], ['COVID/Covid (81).png', 0, 'COVID'], ['COVID/Covid (77).png', 0, 'COVID'], ['COVID/Covid (86).png', 0, 'COVID'], ['COVID/Covid (76).png', 0, 'COVID'], ['COVID/Covid (83).png', 0, 'COVID'], ['COVID/Covid (78).png', 0, 'COVID'], ['COVID/Covid (8).png', 0, 'COVID'], ['COVID/Covid (71).png', 0, 'COVID'], ['COVID/Covid (79).png', 0, 'COVID'], ['COVID/Covid (75).png', 0, 'COVID'], ['COVID/Covid (7).png', 0, 'COVID'], ['COVID/Covid (84).png', 0, 'COVID'], ['COVID/Covid (70).png', 0, 'COVID'], ['COVID/Covid (82).png', 0, 'COVID'], ['COVID/Covid (85).png', 0, 'COVID'], ['COVID/Covid (72).png', 0, 'COVID'], ['COVID/Covid (74).png', 0, 'COVID'], ['COVID/Covid (80).png', 0, 'COVID'], ['COVID/Covid (90).png', 0, 'COVID'], ['COVID/Covid (89).png', 0, 'COVID'], ['COVID/Covid (94).png', 0, 'COVID'], ['COVID/Covid (93).png', 0, 'COVID'], ['COVID/Covid (95).png', 0, 'COVID'], ['COVID/Covid (98).png', 0, 'COVID'], ['COVID/Covid (87).png', 0, 'COVID'], ['COVID/Covid (96).png', 0, 'COVID'], ['COVID/Covid (88).png', 0, 'COVID'], ['COVID/Covid (99).png', 0, 'COVID'], ['COVID/Covid (91).png', 0, 'COVID'], ['COVID/Covid (97).png', 0, 'COVID'], ['COVID/Covid (92).png', 0, 'COVID'], ['COVID/Covid (9).png', 0, 'COVID'], ['non-COVID/Non-Covid (100).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (10).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (1).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (12).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (11).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (15).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (24).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (16).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (13).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (22).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (25).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (29).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (18).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (17).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (3).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (27).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (30).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (23).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (19).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (28).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (14).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (26).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (31).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (2).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (21).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (20).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (43).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (44).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (47).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (33).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (45).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (38).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (42).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (36).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (40).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (35).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (37).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (4).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (39).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (34).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (49).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (46).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (48).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (32).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (41).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (5).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (64).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (61).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (53).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (50).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (62).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (52).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (66).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (59).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (63).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (58).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (6).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (57).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (65).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (60).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (54).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (51).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (55).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (56).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (79).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (7).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (70).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (80).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (72).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (74).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (85).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (69).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (78).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (81).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (76).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (71).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (84).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (83).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (75).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (77).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (82).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (8).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (67).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (68).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (73).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (98).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (93).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (86).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (90).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (9).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (91).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (94).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (96).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (97).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (88).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (89).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (92).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (99).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (95).png', 1, 'non-COVID'], ['non-COVID/Non-Covid (87).png', 1, 'non-COVID']]\n","                             File  DiseaseID Disease Type\n","0             COVID/Covid (1).png          0        COVID\n","1           COVID/Covid (100).png          0        COVID\n","2            COVID/Covid (10).png          0        COVID\n","3            COVID/Covid (12).png          0        COVID\n","4            COVID/Covid (11).png          0        COVID\n","..                            ...        ...          ...\n","195  non-COVID/Non-Covid (89).png          1    non-COVID\n","196  non-COVID/Non-Covid (92).png          1    non-COVID\n","197  non-COVID/Non-Covid (99).png          1    non-COVID\n","198  non-COVID/Non-Covid (95).png          1    non-COVID\n","199  non-COVID/Non-Covid (87).png          1    non-COVID\n","\n","[200 rows x 3 columns]\n","                             File  DiseaseID Disease Type\n","95           COVID/Covid (99).png          0        COVID\n","15           COVID/Covid (26).png          0        COVID\n","30           COVID/Covid (36).png          0        COVID\n","158  non-COVID/Non-Covid (65).png          1    non-COVID\n","128  non-COVID/Non-Covid (47).png          1    non-COVID\n","..                            ...        ...          ...\n","106  non-COVID/Non-Covid (24).png          1    non-COVID\n","14           COVID/Covid (19).png          0        COVID\n","92           COVID/Covid (87).png          0        COVID\n","179  non-COVID/Non-Covid (77).png          1    non-COVID\n","102   non-COVID/Non-Covid (1).png          1    non-COVID\n","\n","[200 rows x 3 columns]\n","[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n","  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n","  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n","  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n","  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n","  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n"," 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n"," 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n"," 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n"," 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n"," 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n"," 198 199]\n"]}],"source":["class_type = ['COVID','non-COVID']\n","data_dir = '/content/drive/MyDrive/deep learning/data'\n","train_dir = os.path.join(data_dir)\n","\n","train_data = []\n","for defects_id, sp in enumerate(class_type):\n","    print(defects_id, sp)\n","    for file in os.listdir(os.path.join(train_dir, sp)):\n","      train_data.append(['{}/{}'.format(sp,file),defects_id, sp])\n","\n","print(train_data)\n","train = pd. DataFrame(train_data, columns = ['File', 'DiseaseID', 'Disease Type'])\n","print(train)\n","SEED = 42\n","train = train.sample(frac=1, random_state = SEED)\n","train_index = np.arange(len(train))\n","print(train)\n","print(train_index)"]},{"cell_type":"code","source":[],"metadata":{"id":"QfGJPvxF6gAJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716274265995,"user_tz":-180,"elapsed":4545,"user":{"displayName":"muammer türkoğlu","userId":"14813586314427592235"}},"outputId":"88a4de11-918a-41be-b1f9-d0d4af803351"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jx8rFRBd0DJF"},"outputs":[],"source":["IMAGE_SIZE = 128\n","def read_image(filepath):\n","    return cv2.imread(os.path.join(data_dir, filepath)) # Loading a color image is the default flag\n","# Resize image to target size\n","def resize_image(image, image_size):\n","    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84428,"status":"ok","timestamp":1716449593074,"user":{"displayName":"muammer türkoğlu","userId":"14813586314427592235"},"user_tz":-180},"id":"9nNv5_PX0HIQ","outputId":"21777fa8-6338-46a7-c3e2-5d62fba86fed"},"outputs":[{"output_type":"stream","name":"stderr","text":["200it [01:24,  2.38it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Shape: (200, 128, 128, 3)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["X_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n","for i, file in tqdm(enumerate(train['File'].values)):\n","    image = read_image(file)\n","    if image is not None:\n","        X_train[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\n","# Normalize the data\n","X_Train = X_train / 255.\n","print('Train Shape: {}'.format(X_Train.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nydwNkJe0JNq"},"outputs":[],"source":["from keras.utils import to_categorical\n","\n","Y_train = train['DiseaseID'].values\n","Y_train = to_categorical(Y_train)"]},{"cell_type":"markdown","metadata":{"id":"ZO1jjkRU0VVJ"},"source":["**VERİ SETİNİ AYIRMA**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OciZBDeg0Lha"},"outputs":[],"source":["X_train, X_val, Y_train, Y_val = train_test_split(X_Train, Y_train, test_size=0.2, random_state=SEED)"]},{"cell_type":"markdown","source":["**PARAMETRELER**"],"metadata":{"id":"BwGVoeWgZa7w"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFveUb_M0ph2"},"outputs":[],"source":["EPOCHS = 30\n","BATCH_SIZE=4\n","SIZE=128\n","N_ch=3"]},{"cell_type":"markdown","source":["**VGG16 MODEL**"],"metadata":{"id":"tv4WkC9eZfoU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"awtBua8Q0tW4","executionInfo":{"status":"ok","timestamp":1716449593916,"user_tz":-180,"elapsed":914,"user":{"displayName":"muammer türkoğlu","userId":"14813586314427592235"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3825af80-ee7f-4b8e-bcfb-dbd306f953df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 128, 128, 3)       84        \n","                                                                 \n"," vgg16 (Functional)          (None, None, None, 512)   14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 8192)              0         \n","                                                                 \n"," dense (Dense)               (None, 256)               2097408   \n","                                                                 \n"," batch_normalization (Batch  (None, 256)               1024      \n"," Normalization)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256)               0         \n","                                                                 \n"," root (Dense)                (None, 2)                 514       \n","                                                                 \n","=================================================================\n","Total params: 16813718 (64.14 MB)\n","Trainable params: 16813206 (64.14 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 128, 128, 3)       84        \n","                                                                 \n"," vgg16 (Functional)          (None, None, None, 512)   14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 8192)              0         \n","                                                                 \n"," dense (Dense)               (None, 256)               2097408   \n","                                                                 \n"," batch_normalization (Batch  (None, 256)               1024      \n"," Normalization)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256)               0         \n","                                                                 \n"," root (Dense)                (None, 2)                 514       \n","                                                                 \n","=================================================================\n","Total params: 16813718 (64.14 MB)\n","Trainable params: 16813206 (64.14 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n"]}],"source":["\n","from keras.applications.vgg16 import VGG16\n","\n","\n","def build_vgg():\n","    vgg = VGG16(weights='imagenet', include_top=False)\n","\n","    input = Input(shape=(SIZE, SIZE, N_ch))\n","    x = Conv2D(3, (3, 3), padding='same')(input)\n","    x = vgg(x)\n","    x = Flatten(name=\"flatten\")(x)\n","    x = Dropout(0.5)(x)\n","    x = Dense(256, activation='relu')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.5)(x)\n","    # multi output\n","    output = Dense(2,activation = 'softmax', name='root')(x)\n","    # model\n","    model = Model(input,output)\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    model.summary()\n","\n","    return model\n","\n","model_vgg = build_vgg()\n","model_vgg.summary()\n"]},{"cell_type":"markdown","source":["**INCEPTIONRESNETV2 MODEL**"],"metadata":{"id":"9wVS3lFVZsx-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSb4lgTeosql"},"outputs":[],"source":["from keras.applications.inception_resnet_v2 import InceptionResNetV2\n","def build_inres():\n","    inres = InceptionResNetV2(weights='imagenet', include_top=False)\n","\n","    input = Input(shape=(SIZE, SIZE, N_ch))\n","    x = Conv2D(3, (3, 3), padding='same')(input)\n","    x = inres(x)\n","    x = GlobalAveragePooling2D()(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.5)(x)\n","    x = Dense(256, activation='relu')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.5)(x)\n","\n","    # multi output\n","    output = Dense(2,activation = 'softmax', name='root')(x)\n","    model = Model(input,output)\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    model.summary()\n","\n","    return model\n"]},{"cell_type":"markdown","source":["**DENSENET201 MODEL**"],"metadata":{"id":"tecpZ4yqZ248"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AVBAGUUo1VCu"},"outputs":[],"source":["from keras.applications.densenet import DenseNet121\n","def build_densenet():\n","    densenet = DenseNet121(weights='imagenet', include_top=False)\n","\n","    input = Input(shape=(SIZE, SIZE, N_ch))\n","    x = Conv2D(3, (3, 3), padding='same')(input)\n","    x = densenet(x)\n","    x = GlobalAveragePooling2D()(x) # flatten()\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.5)(x)\n","    x = Dense(256, activation='relu')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.5)(x)\n","\n","    # multi output\n","    output = Dense(2,activation = 'softmax', name='root')(x)\n","\n","    # model\n","    model = Model(input,output)\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    model.summary()\n","\n","    return model"]},{"cell_type":"markdown","source":["**EĞİTİM AŞAMASI**"],"metadata":{"id":"pXIogmboZ-6L"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244048,"status":"ok","timestamp":1716287836121,"user":{"displayName":"muammer türkoğlu","userId":"14813586314427592235"},"user_tz":-180},"id":"1BYm3bGe0xFw","outputId":"4081bcf8-586b-42a4-be75-cb24ae348e8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 128, 128, 3)       84        \n","                                                                 \n"," vgg16 (Functional)          (None, None, None, 512)   14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 8192)              0         \n","                                                                 \n"," dense (Dense)               (None, 256)               2097408   \n","                                                                 \n"," batch_normalization (Batch  (None, 256)               1024      \n"," Normalization)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256)               0         \n","                                                                 \n"," root (Dense)                (None, 2)                 514       \n","                                                                 \n","=================================================================\n","Total params: 16813718 (64.14 MB)\n","Trainable params: 16813206 (64.14 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n","29084464/29084464 [==============================] - 0s 0us/step\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 128, 128, 3)       84        \n","                                                                 \n"," densenet121 (Functional)    (None, None, None, 1024   7037504   \n","                             )                                   \n","                                                                 \n"," global_average_pooling2d (  (None, 1024)              0         \n"," GlobalAveragePooling2D)                                         \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 1024)              4096      \n"," chNormalization)                                                \n","                                                                 \n"," dropout_2 (Dropout)         (None, 1024)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               262400    \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 256)               1024      \n"," chNormalization)                                                \n","                                                                 \n"," dropout_3 (Dropout)         (None, 256)               0         \n","                                                                 \n"," root (Dense)                (None, 2)                 514       \n","                                                                 \n","=================================================================\n","Total params: 7305622 (27.87 MB)\n","Trainable params: 7219414 (27.54 MB)\n","Non-trainable params: 86208 (336.75 KB)\n","_________________________________________________________________\n","Epoch 1/30\n","40/40 - 16s - loss: 1.1929 - accuracy: 0.5437 - val_loss: 0.7499 - val_accuracy: 0.5500 - 16s/epoch - 398ms/step\n","Epoch 2/30\n","40/40 - 2s - loss: 1.2935 - accuracy: 0.4750 - val_loss: 1.4687 - val_accuracy: 0.4500 - 2s/epoch - 38ms/step\n","Epoch 3/30\n","40/40 - 2s - loss: 1.1675 - accuracy: 0.5625 - val_loss: 0.9876 - val_accuracy: 0.4500 - 2s/epoch - 38ms/step\n","Epoch 4/30\n","40/40 - 1s - loss: 1.2774 - accuracy: 0.4375 - val_loss: 0.9326 - val_accuracy: 0.4500 - 1s/epoch - 37ms/step\n","Epoch 5/30\n","40/40 - 1s - loss: 1.1617 - accuracy: 0.5250 - val_loss: 0.7473 - val_accuracy: 0.4500 - 1s/epoch - 37ms/step\n","Epoch 6/30\n","40/40 - 1s - loss: 1.2809 - accuracy: 0.5125 - val_loss: 0.8296 - val_accuracy: 0.4500 - 1s/epoch - 37ms/step\n","Epoch 7/30\n","40/40 - 1s - loss: 1.0348 - accuracy: 0.5312 - val_loss: 0.7019 - val_accuracy: 0.5500 - 1s/epoch - 37ms/step\n","Epoch 8/30\n","40/40 - 2s - loss: 1.1345 - accuracy: 0.5188 - val_loss: 2.2647 - val_accuracy: 0.5500 - 2s/epoch - 38ms/step\n","Epoch 9/30\n","40/40 - 2s - loss: 1.2913 - accuracy: 0.4812 - val_loss: 2.7389 - val_accuracy: 0.5500 - 2s/epoch - 38ms/step\n","Epoch 10/30\n","40/40 - 2s - loss: 1.2795 - accuracy: 0.4812 - val_loss: 1.6415 - val_accuracy: 0.5500 - 2s/epoch - 40ms/step\n","Epoch 11/30\n","40/40 - 2s - loss: 1.2369 - accuracy: 0.5188 - val_loss: 1.5771 - val_accuracy: 0.5500 - 2s/epoch - 39ms/step\n","Epoch 12/30\n","40/40 - 2s - loss: 1.1872 - accuracy: 0.5312 - val_loss: 2.3338 - val_accuracy: 0.5500 - 2s/epoch - 38ms/step\n","Epoch 13/30\n","40/40 - 1s - loss: 1.1096 - accuracy: 0.5063 - val_loss: 1.3335 - val_accuracy: 0.5500 - 1s/epoch - 37ms/step\n","Epoch 14/30\n","40/40 - 1s - loss: 1.0207 - accuracy: 0.6125 - val_loss: 1.3250 - val_accuracy: 0.4500 - 1s/epoch - 37ms/step\n","Epoch 15/30\n","40/40 - 2s - loss: 1.2720 - accuracy: 0.5250 - val_loss: 1.1119 - val_accuracy: 0.4500 - 2s/epoch - 38ms/step\n","Epoch 16/30\n","40/40 - 2s - loss: 1.1467 - accuracy: 0.5063 - val_loss: 0.9680 - val_accuracy: 0.4500 - 2s/epoch - 39ms/step\n","Epoch 17/30\n","40/40 - 2s - loss: 1.1497 - accuracy: 0.5500 - val_loss: 1.2722 - val_accuracy: 0.4500 - 2s/epoch - 48ms/step\n","Epoch 18/30\n","40/40 - 2s - loss: 1.2475 - accuracy: 0.5125 - val_loss: 0.6952 - val_accuracy: 0.5500 - 2s/epoch - 39ms/step\n","Epoch 19/30\n","40/40 - 2s - loss: 1.1886 - accuracy: 0.4938 - val_loss: 0.7228 - val_accuracy: 0.5500 - 2s/epoch - 40ms/step\n","Epoch 20/30\n","40/40 - 2s - loss: 1.1045 - accuracy: 0.5125 - val_loss: 0.7162 - val_accuracy: 0.5500 - 2s/epoch - 38ms/step\n","Epoch 21/30\n","40/40 - 1s - loss: 1.2041 - accuracy: 0.4375 - val_loss: 0.7817 - val_accuracy: 0.4500 - 1s/epoch - 37ms/step\n","Epoch 22/30\n","40/40 - 1s - loss: 1.1883 - accuracy: 0.4688 - val_loss: 0.6909 - val_accuracy: 0.5500 - 1s/epoch - 37ms/step\n","Epoch 23/30\n","40/40 - 2s - loss: 1.0395 - accuracy: 0.5250 - val_loss: 0.9994 - val_accuracy: 0.5500 - 2s/epoch - 39ms/step\n","Epoch 24/30\n","40/40 - 1s - loss: 1.2846 - accuracy: 0.4250 - val_loss: 1.1107 - val_accuracy: 0.5500 - 1s/epoch - 37ms/step\n","Epoch 25/30\n","40/40 - 2s - loss: 1.0787 - accuracy: 0.4688 - val_loss: 0.9242 - val_accuracy: 0.5500 - 2s/epoch - 39ms/step\n","Epoch 26/30\n","40/40 - 2s - loss: 1.0772 - accuracy: 0.5188 - val_loss: 0.7375 - val_accuracy: 0.5500 - 2s/epoch - 43ms/step\n","Epoch 27/30\n","40/40 - 2s - loss: 1.0435 - accuracy: 0.5312 - val_loss: 0.6911 - val_accuracy: 0.5750 - 2s/epoch - 40ms/step\n","Epoch 28/30\n","40/40 - 2s - loss: 1.0005 - accuracy: 0.5375 - val_loss: 0.6875 - val_accuracy: 0.5500 - 2s/epoch - 43ms/step\n","Epoch 29/30\n","40/40 - 2s - loss: 1.1063 - accuracy: 0.4812 - val_loss: 0.6931 - val_accuracy: 0.5500 - 2s/epoch - 42ms/step\n","Epoch 30/30\n","40/40 - 2s - loss: 0.9642 - accuracy: 0.5188 - val_loss: 0.7128 - val_accuracy: 0.4500 - 2s/epoch - 45ms/step\n","Epoch 1/30\n","40/40 - 76s - loss: 1.3224 - accuracy: 0.5500 - val_loss: 0.7391 - val_accuracy: 0.5750 - 76s/epoch - 2s/step\n","Epoch 2/30\n","40/40 - 3s - loss: 0.7112 - accuracy: 0.6875 - val_loss: 0.7814 - val_accuracy: 0.6250 - 3s/epoch - 81ms/step\n","Epoch 3/30\n","40/40 - 4s - loss: 0.6177 - accuracy: 0.7375 - val_loss: 0.7211 - val_accuracy: 0.6000 - 4s/epoch - 99ms/step\n","Epoch 4/30\n","40/40 - 3s - loss: 0.6036 - accuracy: 0.8125 - val_loss: 0.7814 - val_accuracy: 0.6250 - 3s/epoch - 73ms/step\n","Epoch 5/30\n","40/40 - 3s - loss: 0.4474 - accuracy: 0.8313 - val_loss: 0.8853 - val_accuracy: 0.6000 - 3s/epoch - 72ms/step\n","Epoch 6/30\n","40/40 - 3s - loss: 0.4262 - accuracy: 0.8500 - val_loss: 0.5731 - val_accuracy: 0.6250 - 3s/epoch - 73ms/step\n","Epoch 7/30\n","40/40 - 4s - loss: 0.4223 - accuracy: 0.8250 - val_loss: 0.4685 - val_accuracy: 0.7250 - 4s/epoch - 105ms/step\n","Epoch 8/30\n","40/40 - 3s - loss: 0.6416 - accuracy: 0.8000 - val_loss: 0.3895 - val_accuracy: 0.8000 - 3s/epoch - 73ms/step\n","Epoch 9/30\n","40/40 - 3s - loss: 0.2886 - accuracy: 0.8625 - val_loss: 0.2906 - val_accuracy: 0.9000 - 3s/epoch - 71ms/step\n","Epoch 10/30\n","40/40 - 3s - loss: 0.4037 - accuracy: 0.8375 - val_loss: 0.2220 - val_accuracy: 0.9250 - 3s/epoch - 71ms/step\n","Epoch 11/30\n","40/40 - 4s - loss: 0.3961 - accuracy: 0.8500 - val_loss: 0.1284 - val_accuracy: 0.9750 - 4s/epoch - 96ms/step\n","Epoch 12/30\n","40/40 - 3s - loss: 0.4214 - accuracy: 0.8375 - val_loss: 0.0785 - val_accuracy: 1.0000 - 3s/epoch - 80ms/step\n","Epoch 13/30\n","40/40 - 3s - loss: 0.2344 - accuracy: 0.8875 - val_loss: 0.0531 - val_accuracy: 0.9750 - 3s/epoch - 72ms/step\n","Epoch 14/30\n","40/40 - 3s - loss: 0.2904 - accuracy: 0.8813 - val_loss: 0.0025 - val_accuracy: 1.0000 - 3s/epoch - 73ms/step\n","Epoch 15/30\n","40/40 - 3s - loss: 0.2418 - accuracy: 0.9125 - val_loss: 0.0154 - val_accuracy: 1.0000 - 3s/epoch - 87ms/step\n","Epoch 16/30\n","40/40 - 4s - loss: 0.2894 - accuracy: 0.9187 - val_loss: 0.0023 - val_accuracy: 1.0000 - 4s/epoch - 91ms/step\n","Epoch 17/30\n","40/40 - 3s - loss: 0.2007 - accuracy: 0.9062 - val_loss: 0.0059 - val_accuracy: 1.0000 - 3s/epoch - 72ms/step\n","Epoch 18/30\n","40/40 - 3s - loss: 0.5049 - accuracy: 0.8188 - val_loss: 0.0190 - val_accuracy: 1.0000 - 3s/epoch - 72ms/step\n","Epoch 19/30\n","40/40 - 3s - loss: 0.2279 - accuracy: 0.9125 - val_loss: 0.0043 - val_accuracy: 1.0000 - 3s/epoch - 76ms/step\n","Epoch 20/30\n","40/40 - 4s - loss: 0.2671 - accuracy: 0.8938 - val_loss: 0.0024 - val_accuracy: 1.0000 - 4s/epoch - 98ms/step\n","Epoch 21/30\n","40/40 - 3s - loss: 0.2984 - accuracy: 0.8938 - val_loss: 0.0023 - val_accuracy: 1.0000 - 3s/epoch - 74ms/step\n","Epoch 22/30\n","40/40 - 3s - loss: 0.2152 - accuracy: 0.9312 - val_loss: 0.0123 - val_accuracy: 1.0000 - 3s/epoch - 72ms/step\n","Epoch 23/30\n","40/40 - 3s - loss: 0.2647 - accuracy: 0.9062 - val_loss: 0.0015 - val_accuracy: 1.0000 - 3s/epoch - 73ms/step\n","Epoch 24/30\n","40/40 - 4s - loss: 0.3354 - accuracy: 0.8938 - val_loss: 0.0018 - val_accuracy: 1.0000 - 4s/epoch - 100ms/step\n","Epoch 25/30\n","40/40 - 3s - loss: 0.3824 - accuracy: 0.8625 - val_loss: 0.0151 - val_accuracy: 1.0000 - 3s/epoch - 80ms/step\n","Epoch 26/30\n","40/40 - 3s - loss: 0.3354 - accuracy: 0.8875 - val_loss: 0.0140 - val_accuracy: 1.0000 - 3s/epoch - 73ms/step\n","Epoch 27/30\n","40/40 - 3s - loss: 0.3213 - accuracy: 0.9125 - val_loss: 6.1001e-04 - val_accuracy: 1.0000 - 3s/epoch - 71ms/step\n","Epoch 28/30\n","40/40 - 3s - loss: 0.3015 - accuracy: 0.8687 - val_loss: 0.0082 - val_accuracy: 1.0000 - 3s/epoch - 85ms/step\n","Epoch 29/30\n","40/40 - 4s - loss: 0.2409 - accuracy: 0.9312 - val_loss: 0.0453 - val_accuracy: 0.9750 - 4s/epoch - 92ms/step\n","Epoch 30/30\n","40/40 - 3s - loss: 0.2291 - accuracy: 0.9187 - val_loss: 0.0077 - val_accuracy: 1.0000 - 3s/epoch - 73ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x797960ad8d60>"]},"metadata":{},"execution_count":13}],"source":["from keras.applications.vgg16 import VGG16\n","\n","model_vgg = build_vgg()\n","#model_incep = build_inres()\n","model_dense = build_densenet()\n","\n","#Fits the model on batches with real-time data augmentation\n","model_vgg.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n","              epochs=EPOCHS,\n","             verbose=2,\n","            validation_data=(X_val, Y_val))\n","\n","##model_incep.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n","#               epochs=EPOCHS,\n","#               verbose=2,\n","#               validation_data=(X_val, Y_val))\n","\n","model_dense.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n","               epochs=EPOCHS,\n","               verbose=2,\n","               validation_data=(X_val, Y_val))"]},{"cell_type":"markdown","source":["**TEST İŞLEMİ**"],"metadata":{"id":"Oh_3YEM4atx8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kGGydj653NMV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716287856001,"user_tz":-180,"elapsed":17341,"user":{"displayName":"muammer türkoğlu","userId":"14813586314427592235"}},"outputId":"34767e0e-2299-47b9-a038-57bfda4c715d"},"outputs":[{"output_type":"stream","name":"stdout","text":["VGG Modelinin Doğruluk Skoru : 1.0\n","DenseNet201 Modelinin Doğruluk Skoru : 1.0\n"]}],"source":["score_vgg = model_vgg.evaluate(X_val, Y_val, verbose=0)\n","#score_incep = model_incep.evaluate(X_val, Y_val, verbose=0)\n","score_dense = model_dense.evaluate(X_val, Y_val, verbose=0)\n","\n","#print(\"Test loss:\", score[0])\n","print(\"VGG Modelinin Doğruluk Skoru :\", score_dense[1])\n","#print(\"InceptionResNetv2 Modelinin Doğruluk Skoru :\", score_incep[1])\n","print(\"DenseNet201 Modelinin Doğruluk Skoru :\", score_dense[1])"]},{"cell_type":"code","source":["y_pred_vgg = model_vgg.predict(X_val)\n","y_pred_incep = model_incep.predict(X_val)\n","y_pred_dense = model_dense.predict(X_val)\n","\n","y_pred_vgg=np.argmax(y_pred_vgg, axis=1)\n","y_pred_incep=np.argmax(y_pred_incep, axis=1)\n","y_pred_dense=np.argmax(y_pred_dense, axis=1)\n","\n","Y_val=np.argmax(Y_val, axis=1)\n","\n","print(\"VGG16 MODEL SONUÇLARI\")\n","print(\"Doğruluk: \",accuracy_score(Y_val, y_pred_vgg))\n","print(\"F1_Skor: \", f1_score(Y_val, y_pred_vgg))\n","print(\"Hassasiyet: \",precision_score(Y_val, y_pred_vgg))\n","print(\"Duyarlılık: \", recall_score(Y_val, y_pred_vgg))\n","\n","print(\"InceptionResNetv2 MODEL SONUÇLARI\")\n","print(\"Doğruluk: \",accuracy_score(Y_val, y_pred_incep))\n","print(\"F1_Skor: \", f1_score(Y_val, y_pred_incep))\n","print(\"Hassasiyet: \",precision_score(Y_val, y_pred_incep))\n","print(\"Duyarlılık: \", recall_score(Y_val, y_pred_incep))\n","\n","print(\"DenseNet201 MODEL SONUÇLARI\")\n","print(\"Doğruluk: \",accuracy_score(Y_val, y_pred_dense))\n","print(\"F1_Skor: \", f1_score(Y_val, y_pred_dense))\n","print(\"Hassasiyet: \",precision_score(Y_val, y_pred_dense))\n","print(\"Duyarlılık: \", recall_score(Y_val, y_pred_dense))"],"metadata":{"id":"b52mt4DkepcY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652200913396,"user_tz":-180,"elapsed":5866,"user":{"displayName":"Muammer TÜRKOĞLU","userId":"18095441018593478633"}},"outputId":"b83fb017-457c-40df-f8a0-48a6e0dd5ab7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VGG16 MODEL SONUÇLARI\n","Doğruluk:  0.525\n","F1_Skor:  0.0\n","Hassasiyet:  0.0\n","Duyarlılık:  0.0\n","InceptionResNetv2 MODEL SONUÇLARI\n","Doğruluk:  0.9083333333333333\n","F1_Skor:  0.905982905982906\n","Hassasiyet:  0.8833333333333333\n","Duyarlılık:  0.9298245614035088\n","DenseNet201 MODEL SONUÇLARI\n","Doğruluk:  0.8666666666666667\n","F1_Skor:  0.8709677419354839\n","Hassasiyet:  0.8059701492537313\n","Duyarlılık:  0.9473684210526315\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["# VGG16 accuracy plot (hist_vgg16 yerine diğerleri (hist_dense gibi) yazılabilir)\n","plt.plot(hist_vgg16.history['accuracy'])\n","plt.plot(hist_vgg16.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","# VGG16 loss plot\n","plt.plot(hist_vgg16.history['loss'])\n","plt.plot(hist_vgg16.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"uObVVEK4eqUy"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}